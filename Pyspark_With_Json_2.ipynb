{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0ca3291-ebff-4513-a00d-8342c9f587ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 204 bytes.\nWrote 163 bytes.\nWrote 249 bytes.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the sample files.\n",
    "\n",
    "# A regular JSON file.\n",
    "dbutils.fs.put(\"/tmp/test1.json\", \n",
    "'''{ \"Text1\":\"hello\", \"Text2\":\"goodbye\", \"Num1\":5, \"Array1\":[7,8,9] }\n",
    "{ \"Text1\":\"this\", \"Text2\":\"that\", \"Num1\":6.6, \"Array1\":[77,88,99] }\n",
    "{ \"Text1\":\"yes\", \"Text2\":\"no\", \"Num1\":-0.03, \"Array1\":[555,444,222] }''', \n",
    "True)\n",
    "\n",
    "# A text file that contains one JSON field. \n",
    "# We use vertical bar as the field separator because that eliminates problems with quotes and commas inside the JSON.\n",
    "dbutils.fs.put(\"/tmp/test2.txt\", \n",
    "'''Text1|Text2|Num1|JSON1\n",
    "hello | goodbye | 5 | {\"Sub1\":\"john\", \"Sub2\":3}\n",
    "this | that | 6.6 | {\"Sub1\":\"betty\", \"Sub2\":4}\n",
    "yes | no | -0.03 | {\"Sub1\":\"bobby\", \"Sub2\":5}''',\n",
    "True)\n",
    "\n",
    "# A text file that contains one JSON field that is an array of objects. \n",
    "dbutils.fs.put(\"/tmp/test3.txt\", \n",
    "'''Text1|Text2|Num1|JSON1\n",
    "hello | goodbye | 5 | [{\"Sub1\":\"stop\", \"Sub2\":3}, {\"Sub1\":\"go\", \"Sub2\":6}]\n",
    "this | that | 6.6 | [{\"Sub1\":\"eggs\", \"Sub2\":4}, {\"Sub1\":\"bacon\", \"Sub2\":8}]\n",
    "yes | no | -0.03 | [{\"Sub1\":\"apple\", \"Sub2\":5}, {\"Sub1\":\"pear\", \"Sub2\":10}]''',\n",
    "True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c52507d-1644-4fc1-bb00-24f5402356b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/tmp/test1.json', name='test1.json', size=204, modificationTime=1733126510000),\n",
       " FileInfo(path='dbfs:/tmp/test2.txt', name='test2.txt', size=163, modificationTime=1733126510000),\n",
       " FileInfo(path='dbfs:/tmp/test3.txt', name='test3.txt', size=249, modificationTime=1733126510000)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the presence of the files in the Databricks file system.\n",
    "\n",
    "dbutils.fs.ls(\"/tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1519617e-6649-44d8-bd41-12d26f333a05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'{ \"Text1\":\"hello\", \"Text2\":\"goodbye\", \"Num1\":5, \"Array1\":[7,8,9] }\\n{ \"Text1\":\"this\", \"Text2\":\"that\", \"Num1\":6.6, \"Array1\":[77,88,99] }\\n{ \"Text1\":\"yes\", \"Text2\":\"no\", \"Num1\":-0.03, \"Array1\":[555,444,222] }'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the file that contains plain JSON.\n",
    "\n",
    "dbutils.fs.head(\"/tmp/test1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd197608-ac4f-4338-b09d-28bb18f425b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Array1</th><th>Num1</th><th>Text1</th><th>Text2</th></tr></thead><tbody><tr><td>List(7, 8, 9)</td><td>5.0</td><td>hello</td><td>goodbye</td></tr><tr><td>List(77, 88, 99)</td><td>6.6</td><td>this</td><td>that</td></tr><tr><td>List(555, 444, 222)</td><td>-0.03</td><td>yes</td><td>no</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          7,
          8,
          9
         ],
         5.0,
         "hello",
         "goodbye"
        ],
        [
         [
          77,
          88,
          99
         ],
         6.6,
         "this",
         "that"
        ],
        [
         [
          555,
          444,
          222
         ],
         -0.03,
         "yes",
         "no"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Array1",
         "type": "{\"type\":\"array\",\"elementType\":\"long\",\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "Num1",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "Text1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Text2",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make a DataFrame from this file. PySpark will infer the data types of the JSON elements.\n",
    "\n",
    "test1DF = spark.read.json(\"/tmp/test1.json\")\n",
    "\n",
    "# Show the DataFrame. Note that the data is no longer in JSON format. All the JSON syntax has been stripped out and we have regular data fields.\n",
    "\n",
    "display (test1DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71d24755-9524-40f0-b7ce-3b2bb39d0247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+--------+\n| Num1|Text1|  Text2|SplitCol|\n+-----+-----+-------+--------+\n|  5.0|hello|goodbye|       7|\n|  5.0|hello|goodbye|       8|\n|  5.0|hello|goodbye|       9|\n|  6.6| this|   that|      77|\n|  6.6| this|   that|      88|\n|  6.6| this|   that|      99|\n|-0.03|  yes|     no|     555|\n|-0.03|  yes|     no|     444|\n|-0.03|  yes|     no|     222|\n+-----+-----+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode_outer , split , explode,col , when,udf\n",
    "\n",
    "Columns = test1DF.columns\n",
    "\n",
    "def ColumnsName(Columns):\n",
    "  for x in Columns:\n",
    "    yield (\"'\" + x + \"'\")\n",
    "\n",
    "ColumnNameUdf = udf(lambda list : ColumnsName(list))\n",
    "\n",
    "# ColumnsStr = \"\"\n",
    "# Pos = 0\n",
    "# for i in Columns:\n",
    "#   if Pos != (len(Columns) - 1):\n",
    "#     ColumnsStr = ColumnsStr + \"'\" + str(i) + \"',\"\n",
    "#   else:\n",
    "#     ColumnsStr = ColumnsStr + \"'\" + str(i) + \"'\"\n",
    "#   Pos = Pos + 1\n",
    "\n",
    "# test1DFupdated = test1DF.select(test1DF.columns,explode_outer(test1DF.Array1).alias(\"SplitCol\"))\n",
    "test1DFupdated = test1DF.select(\"Num1\",\"Text1\",\"Text2\",explode_outer(test1DF.Array1).alias(\"SplitCol\"))\n",
    "# display(test1DF.select(explode_outer(test1DF.Array1)))\n",
    "test1DFupdated.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fcfc682-0774-4225-b472-1e4593f36df2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Text1|Text2|Num1|JSON1\\nhello | goodbye | 5 | {\"Sub1\":\"john\", \"Sub2\":3}\\nthis | that | 6.6 | {\"Sub1\":\"betty\", \"Sub2\":4}\\nyes | no | -0.03 | {\"Sub1\":\"bobby\", \"Sub2\":5}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the file with regular fields and one field with JSON text.\n",
    "\n",
    "dbutils.fs.head(\"/tmp/test2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "744c305b-c238-4fc4-a0ae-c8eee57f6335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Text1</th><th>Text2</th><th>Num1</th><th>JSON1</th></tr></thead><tbody><tr><td>hello </td><td> goodbye </td><td>5.0</td><td> {\"Sub1\":\"john\", \"Sub2\":3}</td></tr><tr><td>this </td><td> that </td><td>6.6</td><td> {\"Sub1\":\"betty\", \"Sub2\":4}</td></tr><tr><td>yes </td><td> no </td><td>-0.03</td><td> {\"Sub1\":\"bobby\", \"Sub2\":5}</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "hello ",
         " goodbye ",
         5.0,
         " {\"Sub1\":\"john\", \"Sub2\":3}"
        ],
        [
         "this ",
         " that ",
         6.6,
         " {\"Sub1\":\"betty\", \"Sub2\":4}"
        ],
        [
         "yes ",
         " no ",
         -0.03,
         " {\"Sub1\":\"bobby\", \"Sub2\":5}"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Text1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Text2",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Num1",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "JSON1",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a DataFrame from the text file that contains a JSON field.\n",
    "\n",
    "# This is a small file, so we can infer the schema. For a large file, you should use .schema().\n",
    "test2DF = spark.read.option(\"inferSchema\", True).option(\"header\", True).option(\"delimiter\", \"|\").csv(\"/tmp/test2.txt\")\n",
    "\n",
    "# Show the DataFrame. Note that the JSON field is plain text; we cannot pick out its sub-fields.\n",
    "display (test2DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acc17aa2-1fe1-49a1-aa9a-6795336c139d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Text1</th><th>Text2</th><th>Num1</th><th>JSON1</th><th>JSON1_Sub2</th></tr></thead><tbody><tr><td>hello </td><td> goodbye </td><td>5.0</td><td>List(john, 3)</td><td>3</td></tr><tr><td>this </td><td> that </td><td>6.6</td><td>List(betty, 4)</td><td>4</td></tr><tr><td>yes </td><td> no </td><td>-0.03</td><td>List(bobby, 5)</td><td>5</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "hello ",
         " goodbye ",
         5.0,
         [
          "john",
          3
         ],
         3
        ],
        [
         "this ",
         " that ",
         6.6,
         [
          "betty",
          4
         ],
         4
        ],
        [
         "yes ",
         " no ",
         -0.03,
         [
          "bobby",
          5
         ],
         5
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Text1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Text2",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Num1",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "JSON1",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"Sub1\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Sub2\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "JSON1_Sub2",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change the JSON string into a struct, so we can get its parts. Then pull out one of those parts.\n",
    "\n",
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Define the schema of the JSON string.\n",
    "schema = StructType([\n",
    "  StructField(\"Sub1\", StringType()), \n",
    "  StructField(\"Sub2\", IntegerType())\n",
    "])\n",
    "\n",
    "# Use the schema to change the JSON string into a struct, overwriting the JSON string.\n",
    "test2DF = test2DF.withColumn(\"JSON1\", from_json(col(\"JSON1\"), schema))\n",
    "\n",
    "# Make a separate column from one of the struct fields.\n",
    "test2DF = test2DF.withColumn(\"JSON1_Sub2\", col(\"JSON1.Sub2\"))\n",
    "\n",
    "display (test2DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a6f8f4a-ff7f-438e-87df-c3708e7eeb1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Text1|Text2|Num1|JSON1\\nhello | goodbye | 5 | [{\"Sub1\":\"stop\", \"Sub2\":3}, {\"Sub1\":\"go\", \"Sub2\":6}]\\nthis | that | 6.6 | [{\"Sub1\":\"eggs\", \"Sub2\":4}, {\"Sub1\":\"bacon\", \"Sub2\":8}]\\nyes | no | -0.03 | [{\"Sub1\":\"apple\", \"Sub2\":5}, {\"Sub1\":\"pear\", \"Sub2\":10}]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the file that contains an array of JSON objects.\n",
    "\n",
    "dbutils.fs.head(\"/tmp/test3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afc6d2bb-7b09-4c48-8ed1-9d7fd2713a5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Text1</th><th>Text2</th><th>Num1</th><th>JSON1</th></tr></thead><tbody><tr><td>hello </td><td> goodbye </td><td>5.0</td><td> [{\"Sub1\":\"stop\", \"Sub2\":3}, {\"Sub1\":\"go\", \"Sub2\":6}]</td></tr><tr><td>this </td><td> that </td><td>6.6</td><td> [{\"Sub1\":\"eggs\", \"Sub2\":4}, {\"Sub1\":\"bacon\", \"Sub2\":8}]</td></tr><tr><td>yes </td><td> no </td><td>-0.03</td><td> [{\"Sub1\":\"apple\", \"Sub2\":5}, {\"Sub1\":\"pear\", \"Sub2\":10}]</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "hello ",
         " goodbye ",
         5.0,
         " [{\"Sub1\":\"stop\", \"Sub2\":3}, {\"Sub1\":\"go\", \"Sub2\":6}]"
        ],
        [
         "this ",
         " that ",
         6.6,
         " [{\"Sub1\":\"eggs\", \"Sub2\":4}, {\"Sub1\":\"bacon\", \"Sub2\":8}]"
        ],
        [
         "yes ",
         " no ",
         -0.03,
         " [{\"Sub1\":\"apple\", \"Sub2\":5}, {\"Sub1\":\"pear\", \"Sub2\":10}]"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Text1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Text2",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Num1",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "JSON1",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a DataFrame from the text file that contains a JSON array.\n",
    "\n",
    "test3DF = spark.read.option(\"inferSchema\", True).option(\"header\", True).option(\"delimiter\", \"|\").csv(\"/tmp/test3.txt\")\n",
    "\n",
    "display (test3DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b25fcd93-7b00-4a62-be3a-24a885ca28db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----+-----+----+\n| Text1|    Text2| Num1| Sub1|Sub2|\n+------+---------+-----+-----+----+\n|hello | goodbye |  5.0| stop|   3|\n|hello | goodbye |  5.0|   go|   6|\n| this |    that |  6.6| eggs|   4|\n| this |    that |  6.6|bacon|   8|\n|  yes |      no |-0.03|apple|   5|\n|  yes |      no |-0.03| pear|  10|\n+------+---------+-----+-----+----+\n\n"
     ]
    }
   ],
   "source": [
    "DFSplit = test3DF.select(\"Text1\",\"Text2\",\"Num1\",\"JSON1obj.*\")\n",
    "DFSplit.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6116496a-76aa-4303-9f2a-077ef8404f87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Text1</th><th>Text2</th><th>Num1</th><th>JSON1arr</th></tr></thead><tbody><tr><td>hello </td><td> goodbye </td><td>5.0</td><td>List(List(stop, 3), List(go, 6))</td></tr><tr><td>this </td><td> that </td><td>6.6</td><td>List(List(eggs, 4), List(bacon, 8))</td></tr><tr><td>yes </td><td> no </td><td>-0.03</td><td>List(List(apple, 5), List(pear, 10))</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "hello ",
         " goodbye ",
         5.0,
         [
          [
           "stop",
           3
          ],
          [
           "go",
           6
          ]
         ]
        ],
        [
         "this ",
         " that ",
         6.6,
         [
          [
           "eggs",
           4
          ],
          [
           "bacon",
           8
          ]
         ]
        ],
        [
         "yes ",
         " no ",
         -0.03,
         [
          [
           "apple",
           5
          ],
          [
           "pear",
           10
          ]
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Text1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Text2",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Num1",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "JSON1arr",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"Sub1\",\"type\":\"string\",\"nullable\":false,\"metadata\":{}},{\"name\":\"Sub2\",\"type\":\"integer\",\"nullable\":false,\"metadata\":{}}]},\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change the JSON field to a true array.\n",
    "\n",
    "# Credit to https://kontext.tech/column/spark/284/pyspark-convert-json-string-column-to-array-of-object-structtype-in-data-frame\n",
    "\n",
    "from pyspark.sql.functions import from_json, col, split, udf\n",
    "from pyspark.sql.types import *\n",
    "import json\n",
    "\n",
    "# Schema for the array of JSON objects.\n",
    "json_array_schema = ArrayType(\n",
    "  StructType([\n",
    "    StructField('Sub1', StringType(), nullable=False), \n",
    "    StructField('Sub2', IntegerType(), nullable=False)\n",
    "  ])\n",
    ")\n",
    "\n",
    "# Create function to parse JSON using standard Python json library.\n",
    "def parse_json(array_str):\n",
    "  json_obj = json.loads(array_str)\n",
    "  for item in json_obj:\n",
    "    yield (item['Sub1'], item['Sub2'])\n",
    "\n",
    "# Create a UDF, whose return type of the JSON schema defined above.    \n",
    "parse_json_udf = udf(lambda str: parse_json(str), json_array_schema)\n",
    "  \n",
    "# Use the UDF to change the JSON string into a true array of objects.\n",
    "test3DF = test3DF.withColumn(\"JSON1arr\", parse_json_udf((col(\"JSON1\"))))\n",
    "\n",
    "# We don't need to JSON text anymore.\n",
    "test3DF = test3DF.drop(\"JSON1\")\n",
    "\n",
    "# We now have an array of structs with named members.\n",
    "display (test3DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce6ac555-b8b4-435b-afcd-4cbe1172bf72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Text1</th><th>Text2</th><th>Num1</th><th>JSON1obj</th></tr></thead><tbody><tr><td>hello </td><td> goodbye </td><td>5.0</td><td>List(stop, 3)</td></tr><tr><td>hello </td><td> goodbye </td><td>5.0</td><td>List(go, 6)</td></tr><tr><td>this </td><td> that </td><td>6.6</td><td>List(eggs, 4)</td></tr><tr><td>this </td><td> that </td><td>6.6</td><td>List(bacon, 8)</td></tr><tr><td>yes </td><td> no </td><td>-0.03</td><td>List(apple, 5)</td></tr><tr><td>yes </td><td> no </td><td>-0.03</td><td>List(pear, 10)</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "hello ",
         " goodbye ",
         5.0,
         [
          "stop",
          3
         ]
        ],
        [
         "hello ",
         " goodbye ",
         5.0,
         [
          "go",
          6
         ]
        ],
        [
         "this ",
         " that ",
         6.6,
         [
          "eggs",
          4
         ]
        ],
        [
         "this ",
         " that ",
         6.6,
         [
          "bacon",
          8
         ]
        ],
        [
         "yes ",
         " no ",
         -0.03,
         [
          "apple",
          5
         ]
        ],
        [
         "yes ",
         " no ",
         -0.03,
         [
          "pear",
          10
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Text1",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Text2",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Num1",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "JSON1obj",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"Sub1\",\"type\":\"string\",\"nullable\":false,\"metadata\":{}},{\"name\":\"Sub2\",\"type\":\"integer\",\"nullable\":false,\"metadata\":{}}]}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The array of structs might be useful as is. But it is sometimes easier to put each array element in its own DataFrame row.\n",
    "\n",
    "from pyspark.sql.functions import col, explode\n",
    "\n",
    "test3DF = test3DF.withColumn(\"JSON1obj\", explode(col(\"JSON1arr\")))\n",
    "\n",
    "# The column with the array is now redundant.\n",
    "test3DF = test3DF.drop(\"JSON1arr\")\n",
    "\n",
    "display (test3DF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb6c2aa3-2f9b-4e47-ab56-cc8e61fcd370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Sub1</th></tr></thead><tbody><tr><td>stop</td></tr><tr><td>go</td></tr><tr><td>eggs</td></tr><tr><td>bacon</td></tr><tr><td>apple</td></tr><tr><td>pear</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "stop"
        ],
        [
         "go"
        ],
        [
         "eggs"
        ],
        [
         "bacon"
        ],
        [
         "apple"
        ],
        [
         "pear"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "Sub1",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a specific named element from all the JSON objects. This is much easier now that we exploded the array.\n",
    "\n",
    "display (test3DF.select(\"JSON1obj.Sub1\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Pyspark_With_Json_2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
