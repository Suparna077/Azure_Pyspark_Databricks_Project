{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3718b2e8-a52d-4702-a0f2-7dde88814bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set( \"fs.azure.account.key.azuredlssup07.dfs.core.windows.net\",\n",
    "  \"access_key_of_account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5b035cb-f4e2-414f-942b-5456c6313904",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.mount(\n",
    "  source = \"wasbs://azuredls07@azuredlssup07.blob.core.windows.net\",\n",
    "  mount_point = \"/mnt/AzureAccount\",\n",
    "  extra_configs = {\"fs.azure.account.key.azuredlssup07.blob.core.windows.net\":\"access_key_of_account\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cbaa387-8806-4482-a15f-142809bf7b9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/mnt/AzureAccount/DatabricksParquet/', name='DatabricksParquet/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/mnt/AzureAccount/Pyspark_With_Json/', name='Pyspark_With_Json/', size=0, modificationTime=0),\n",
       " FileInfo(path='dbfs:/mnt/AzureAccount/YearlyTopTen.csv', name='YearlyTopTen.csv', size=57828, modificationTime=1730564575000),\n",
       " FileInfo(path='dbfs:/mnt/AzureAccount/sample1.parquet', name='sample1.parquet', size=1308, modificationTime=1731602962000)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/mnt/AzureAccount/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "277dd9b1-6dba-4326-a852-862a43039fcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "Json_Data_File = open(\"/dbfs/mnt/AzureAccount/Pyspark_With_Json/dwsample3.json\",\"rb\")\n",
    "Json_Data = json.loads(\"/mnt/AzureAccount/Pyspark_With_Json/dwsample3.json\")\n",
    "print(Json_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6067832a-430a-4f9e-94a9-a27a330f9149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "File_Path = 'abfss://azuredls07@azuredlssup07.dfs.core.windows.net/Pyspark_With_Json/dwsample3.json'\n",
    "Json_DF_Updated = spark.read.format(\"json\").option(\"multiline\",True).load(File_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2ea0d4e-37b9-4935-8b66-9530b21a48e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>address</th><th>age</th><th>firstName</th><th>gender</th><th>lastName</th><th>phoneNumbers</th></tr></thead><tbody><tr><td>List(San Jone, 394221, CA, 126)</td><td>24</td><td>Rack</td><td>man</td><td>Jackon</td><td>List(List(7383627627, home))</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          "San Jone",
          "394221",
          "CA",
          "126"
         ],
         "24",
         "Rack",
         "man",
         "Jackon",
         [
          [
           "7383627627",
           "home"
          ]
         ]
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "address",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"city\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"postalCode\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"state\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"streetAddress\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "age",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "firstName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "gender",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "lastName",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "phoneNumbers",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"number\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"type\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Json_DF_Updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57457888-39fb-46b8-b45c-4f041b419b81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+-------------+---+---------+------+--------+-------------------+\n|    city|postalCode|state|streetAddress|age|firstName|gender|lastname|PhoneNumber_Updated|\n+--------+----------+-----+-------------+---+---------+------+--------+-------------------+\n|San Jone|    394221|   CA|          126| 24|     Rack|   man|  Jackon| {7383627627, home}|\n+--------+----------+-----+-------------+---+---------+------+--------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode_outer\n",
    "\n",
    "Json_Final = Json_DF_Updated.select(\"address.*\",\"age\",\"firstName\",\"gender\",\"lastname\",explode_outer(Json_DF_Updated.phoneNumbers).alias(\"PhoneNumber_Updated\"))\n",
    "Json_Final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cb75878-fd72-4a39-bac4-fc088a59c596",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----+-------------+---+---------+------+--------+----------+----+\n|    city|postalCode|state|streetAddress|age|firstName|gender|lastname|    number|type|\n+--------+----------+-----+-------------+---+---------+------+--------+----------+----+\n|San Jone|    394221|   CA|          126| 24|     Rack|   man|  Jackon|7383627627|home|\n+--------+----------+-----+-------------+---+---------+------+--------+----------+----+\n\n"
     ]
    }
   ],
   "source": [
    "# display(Json_Final)\n",
    "Json_Final.select(\"city\",\"postalCode\",\"state\",\"streetAddress\",\"age\",\"firstName\",\"gender\",\"lastname\",\"PhoneNumber_Updated.*\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a536de17-0eaa-405c-babf-5a952dc0cf84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CHECK</th><th>COL</th><th>DATA</th><th>IFAM</th><th>KTM</th></tr></thead><tbody><tr><td>List(1, TWO)</td><td>21</td><td>List(List(List(List(k1, v1), List(k2, v2)), 31), List(List(List(k3, v3), List(k4, v4)), 33))</td><td>EQR</td><td>1548176931466</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          1,
          "TWO"
         ],
         21,
         [
          [
           [
            [
             "k1",
             "v1"
            ],
            [
             "k2",
             "v2"
            ]
           ],
           "31"
          ],
          [
           [
            [
             "k3",
             "v3"
            ],
            [
             "k4",
             "v4"
            ]
           ],
           "33"
          ]
         ],
         "EQR",
         1548176931466
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "CHECK",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"Check1\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Check2\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "COL",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "DATA",
         "type": "{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"Crate\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"key\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"value\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"MLrate\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true}"
        },
        {
         "metadata": "{}",
         "name": "IFAM",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "KTM",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Json_Sample_DF_2 = spark.read.format(\"json\").option(\"multiline\",True).load(\"/mnt/AzureAccount/Pyspark_With_Json/sample.json\")\n",
    "display(Json_Sample_DF_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "668ca3dd-0e91-4dcd-9d9a-696739578be3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CHECK</th><th>COL</th><th>Temp</th><th>IFAM</th><th>KTM</th></tr></thead><tbody><tr><td>List(1, TWO)</td><td>21</td><td>List(List(List(k1, v1), List(k2, v2)), 31)</td><td>EQR</td><td>1548176931466</td></tr><tr><td>List(1, TWO)</td><td>21</td><td>List(List(List(k3, v3), List(k4, v4)), 33)</td><td>EQR</td><td>1548176931466</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         [
          1,
          "TWO"
         ],
         21,
         [
          [
           [
            "k1",
            "v1"
           ],
           [
            "k2",
            "v2"
           ]
          ],
          "31"
         ],
         "EQR",
         1548176931466
        ],
        [
         [
          1,
          "TWO"
         ],
         21,
         [
          [
           [
            "k3",
            "v3"
           ],
           [
            "k4",
            "v4"
           ]
          ],
          "33"
         ],
         "EQR",
         1548176931466
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "CHECK",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"Check1\",\"type\":\"long\",\"nullable\":true,\"metadata\":{}},{\"name\":\"Check2\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "COL",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "Temp",
         "type": "{\"type\":\"struct\",\"fields\":[{\"name\":\"Crate\",\"type\":{\"type\":\"array\",\"elementType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"key\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"value\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]},\"containsNull\":true},\"nullable\":true,\"metadata\":{}},{\"name\":\"MLrate\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}"
        },
        {
         "metadata": "{}",
         "name": "IFAM",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "KTM",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "JSON_TEMP = Json_Sample_DF_2.select(\"CHECK\",\"COL\",explode_outer(Json_Sample_DF_2.DATA).alias(\"Temp\"),\"IFAM\",\"KTM\")\n",
    "display(JSON_TEMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b75df4dc-117e-45af-b643-28b083b2ca85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3969828442776096>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m JSON_TEMP1 \u001B[38;5;241m=\u001B[39m JSON_TEMP\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCHECK.*\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCOL\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTemp\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIFAM\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKTM\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'select'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AttributeError",
        "evalue": "'NoneType' object has no attribute 'select'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>AttributeError</span>: 'NoneType' object has no attribute 'select'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
        "File \u001B[0;32m<command-3969828442776096>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m JSON_TEMP1 \u001B[38;5;241m=\u001B[39m JSON_TEMP\u001B[38;5;241m.\u001B[39mselect(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCHECK.*\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCOL\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTemp\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIFAM\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKTM\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n",
        "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'select'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "JSON_TEMP1 = JSON_TEMP.select(\"CHECK.*\",\"COL\",\"Temp\",\"IFAM\",\"KTM\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b98fa7f-e6b8-4cdb-b54d-56574709f2a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3969828442776091>, line 9\u001B[0m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m from_json, col\n",
       "\u001B[1;32m      4\u001B[0m PhoneNumbers_schema \u001B[38;5;241m=\u001B[39m StructType([\n",
       "\u001B[1;32m      5\u001B[0m     StructField(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber\u001B[39m\u001B[38;5;124m\"\u001B[39m , IntegerType()),\n",
       "\u001B[1;32m      6\u001B[0m     StructField(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhome\u001B[39m\u001B[38;5;124m\"\u001B[39m ,StringType())\n",
       "\u001B[1;32m      7\u001B[0m ])\n",
       "\u001B[0;32m----> 9\u001B[0m Json_DF_Updated\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphoneNumbers_updated\u001B[39m\u001B[38;5;124m\"\u001B[39m,from_json(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphoneNumbers\u001B[39m\u001B[38;5;124m\"\u001B[39m),PhoneNumbers_schema))\n",
       "\u001B[1;32m     10\u001B[0m Json_DF_Updated\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphoneNumbers\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     11\u001B[0m Json_DF_Updated\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:6282\u001B[0m, in \u001B[0;36mDataFrame.withColumn\u001B[0;34m(self, colName, col)\u001B[0m\n",
       "\u001B[1;32m   6277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, Column):\n",
       "\u001B[1;32m   6278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n",
       "\u001B[1;32m   6279\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_COLUMN\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m   6280\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcol\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(col)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n",
       "\u001B[1;32m   6281\u001B[0m     )\n",
       "\u001B[0;32m-> 6282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mwithColumn(colName, col\u001B[38;5;241m.\u001B[39m_jc), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"from_json(phoneNumbers)\" due to data type mismatch: The first parameter requires the \"STRING\" type, however \"phoneNumbers\" has the type \"ARRAY<STRUCT<number: STRING, type: STRING>>\". SQLSTATE: 42K09;\n",
       "'Project [address#799, age#800, firstName#801, gender#802, lastName#803, phoneNumbers#804, from_json(StructField(Number,IntegerType,true), StructField(home,StringType,true), phoneNumbers#804, Some(Etc/UTC)) AS phoneNumbers_updated#1287]\n",
       "+- Relation [address#799,age#800,firstName#801,gender#802,lastName#803,phoneNumbers#804] json\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"from_json(phoneNumbers)\" due to data type mismatch: The first parameter requires the \"STRING\" type, however \"phoneNumbers\" has the type \"ARRAY<STRUCT<number: STRING, type: STRING>>\". SQLSTATE: 42K09;\n'Project [address#799, age#800, firstName#801, gender#802, lastName#803, phoneNumbers#804, from_json(StructField(Number,IntegerType,true), StructField(home,StringType,true), phoneNumbers#804, Some(Etc/UTC)) AS phoneNumbers_updated#1287]\n+- Relation [address#799,age#800,firstName#801,gender#802,lastName#803,phoneNumbers#804] json\n"
       },
       "metadata": {
        "errorSummary": "[DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"from_json(phoneNumbers)\" due to data type mismatch: The first parameter requires the \"STRING\" type, however \"phoneNumbers\" has the type \"ARRAY<STRUCT<number: STRING, type: STRING>>\". SQLSTATE: 42K09"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": "42K09",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-3969828442776091>, line 9\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m from_json, col\n\u001B[1;32m      4\u001B[0m PhoneNumbers_schema \u001B[38;5;241m=\u001B[39m StructType([\n\u001B[1;32m      5\u001B[0m     StructField(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber\u001B[39m\u001B[38;5;124m\"\u001B[39m , IntegerType()),\n\u001B[1;32m      6\u001B[0m     StructField(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhome\u001B[39m\u001B[38;5;124m\"\u001B[39m ,StringType())\n\u001B[1;32m      7\u001B[0m ])\n\u001B[0;32m----> 9\u001B[0m Json_DF_Updated\u001B[38;5;241m.\u001B[39mwithColumn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphoneNumbers_updated\u001B[39m\u001B[38;5;124m\"\u001B[39m,from_json(col(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphoneNumbers\u001B[39m\u001B[38;5;124m\"\u001B[39m),PhoneNumbers_schema))\n\u001B[1;32m     10\u001B[0m Json_DF_Updated\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mphoneNumbers\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     11\u001B[0m Json_DF_Updated\u001B[38;5;241m.\u001B[39mshow()\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:6282\u001B[0m, in \u001B[0;36mDataFrame.withColumn\u001B[0;34m(self, colName, col)\u001B[0m\n\u001B[1;32m   6277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, Column):\n\u001B[1;32m   6278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m   6279\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_COLUMN\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   6280\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcol\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(col)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[1;32m   6281\u001B[0m     )\n\u001B[0;32m-> 6282\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mwithColumn(colName, col\u001B[38;5;241m.\u001B[39m_jc), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [DATATYPE_MISMATCH.UNEXPECTED_INPUT_TYPE] Cannot resolve \"from_json(phoneNumbers)\" due to data type mismatch: The first parameter requires the \"STRING\" type, however \"phoneNumbers\" has the type \"ARRAY<STRUCT<number: STRING, type: STRING>>\". SQLSTATE: 42K09;\n'Project [address#799, age#800, firstName#801, gender#802, lastName#803, phoneNumbers#804, from_json(StructField(Number,IntegerType,true), StructField(home,StringType,true), phoneNumbers#804, Some(Etc/UTC)) AS phoneNumbers_updated#1287]\n+- Relation [address#799,age#800,firstName#801,gender#802,lastName#803,phoneNumbers#804] json\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType , StructField ,StringType,IntegerType\n",
    "from pyspark.sql.functions import from_json, col\n",
    "\n",
    "PhoneNumbers_schema = StructType([\n",
    "    StructField(\"Number\" , IntegerType()),\n",
    "    StructField(\"home\" ,StringType())\n",
    "])\n",
    "\n",
    "Json_DF_Updated.withColumn(\"phoneNumbers_updated\",from_json(col(\"phoneNumbers\"),PhoneNumbers_schema))\n",
    "Json_DF_Updated.drop(\"phoneNumbers\")\n",
    "Json_DF_Updated.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f44fbd61-f8d8-43fd-80c9-a886c26e6ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='abfss://azuredls07@azuredlssup07.dfs.core.windows.net/Pyspark_With_Json/dwsample3.json', name='dwsample3.json', size=323, modificationTime=1733595814000)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls('abfss://azuredls07@azuredlssup07.dfs.core.windows.net/Pyspark_With_Json/dwsample3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee8e3776-c8e8-4f69-b761-28996d5e101f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 55 bytes.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-355779908317208>, line 7\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# File_Path = 'abfss://azuredls07@azuredlssup07.dfs.core.windows.net/Pyspark_With_Json/dwsample3.json'\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# File_Path_Url = \"https://azuredlssup07.blob.core.windows.net/azuredls07/Pyspark_With_Json/dwsample3.json\"\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mput(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/temp/Json_Sample_Data.json\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      6\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/dbfs/mnt/AzureAccount/Pyspark_With_Json/dwsample3.json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
       "\u001B[0;32m----> 7\u001B[0m Json_Data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/temp/Json_Sample_Data.json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      8\u001B[0m Json_data_Dict \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(Json_Data\u001B[38;5;241m.\u001B[39mread())\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(Json_data_Dict)\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    279\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n",
       "\u001B[1;32m    280\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m    281\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    282\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    283\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    284\u001B[0m     )\n",
       "\u001B[0;32m--> 286\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\n",
       "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/temp/Json_Sample_Data.json'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "FileNotFoundError",
        "evalue": "[Errno 2] No such file or directory: '/temp/Json_Sample_Data.json'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>FileNotFoundError</span>: [Errno 2] No such file or directory: '/temp/Json_Sample_Data.json'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-355779908317208>, line 7\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# File_Path = 'abfss://azuredls07@azuredlssup07.dfs.core.windows.net/Pyspark_With_Json/dwsample3.json'\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# File_Path_Url = \"https://azuredlssup07.blob.core.windows.net/azuredls07/Pyspark_With_Json/dwsample3.json\"\u001B[39;00m\n\u001B[1;32m      5\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mput(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/temp/Json_Sample_Data.json\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      6\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/dbfs/mnt/AzureAccount/Pyspark_With_Json/dwsample3.json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 7\u001B[0m Json_Data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/temp/Json_Sample_Data.json\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      8\u001B[0m Json_data_Dict \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(Json_Data\u001B[38;5;241m.\u001B[39mread())\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(Json_data_Dict)\n",
        "File \u001B[0;32m/databricks/python/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    284\u001B[0m     )\n\u001B[0;32m--> 286\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
        "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/temp/Json_Sample_Data.json'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# File_Path = 'abfss://azuredls07@azuredlssup07.dfs.core.windows.net/Pyspark_With_Json/dwsample3.json'\n",
    "# File_Path_Url = \"https://azuredlssup07.blob.core.windows.net/azuredls07/Pyspark_With_Json/dwsample3.json\"\n",
    "dbutils.fs.put(\"/temp/Json_Sample_Data.json\",\n",
    "                \"/dbfs/mnt/AzureAccount/Pyspark_With_Json/dwsample3.json\", True)\n",
    "Json_Data = open(\"/temp/Json_Sample_Data.json\", \"rb\")\n",
    "Json_data_Dict = json.loads(Json_Data.read())\n",
    "print(Json_data_Dict)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pspark_With_JSON",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
