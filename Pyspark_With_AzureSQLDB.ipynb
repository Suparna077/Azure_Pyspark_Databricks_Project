{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69a493f8-952f-4f93-a66c-a07c03f506af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: [FileInfo(path='dbfs:/mnt/AzureAccount/DatabricksParquet/', name='DatabricksParquet/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/mnt/AzureAccount/Pyspark_With_Json/', name='Pyspark_With_Json/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/mnt/AzureAccount/SampleCSV.csv', name='SampleCSV.csv', size=176, modificationTime=1734508306000),\n FileInfo(path='dbfs:/mnt/AzureAccount/YearlyTopTen.csv', name='YearlyTopTen.csv', size=57828, modificationTime=1730564575000),\n FileInfo(path='dbfs:/mnt/AzureAccount/sample1.parquet', name='sample1.parquet', size=1308, modificationTime=1731602962000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/mnt/AzureAccount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "346a818a-8b0b-41ac-8a57-770ac19aec9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----------+---------+\n| Username| Identifier|First name|Last name|\n+---------+-----------+----------+---------+\n| booker12|       9012|    Rachel|   Booker|\n|   grey07|       2070|     Laura|     Grey|\n|johnson81|       4081|     Craig|  Johnson|\n|jenkins46|       9346|      Mary|  Jenkins|\n|  smith79|       5079|     Jamie|    Smith|\n+---------+-----------+----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "server_name = \"jdbc:sqlserver://suparna07.database.windows.net\"\n",
    "database_name = \"AdventureWorks\"\n",
    "url = server_name + \";\" + \"databaseName=\" + database_name + \";\"\n",
    "\n",
    "table_name = \"Sample07\"\n",
    "username = \"Suparna\"\n",
    "password = \"Rodopsin@7\" # Please specify password here\n",
    "\n",
    "# df = spark.read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").option(\"inferSchema\",\"true\").option(\"header\",\"true\").option(\"delimeter\",\";\").load(\"/mnt/AzureAccount/SampleCSV.csv\")\n",
    "df = spark.read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"/mnt/AzureAccount/SampleCSV.csv\", sep=\";\")\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5cf7ea9-15f6-42fe-9620-f8fe824d3cb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "server_name = \"jdbc:sqlserver://suparna07.database.windows.net\"\n",
    "database_name = \"AdventureWorks\"\n",
    "url = server_name + \";\" + \"databaseName=\" + database_name + \";\"\n",
    "\n",
    "table_name = \"Sample07\"\n",
    "username = \"Suparna\"\n",
    "password = \"Rodopsin@7\" # Please specify password here\n",
    "\n",
    "try:\n",
    "  df.write \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"dbtable\", table_name) \\\n",
    "    .option(\"user\", username) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .save()\n",
    "except ValueError as error :\n",
    "    print(\"Connector write failed\", error)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark_With_AzureSQLDB",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
